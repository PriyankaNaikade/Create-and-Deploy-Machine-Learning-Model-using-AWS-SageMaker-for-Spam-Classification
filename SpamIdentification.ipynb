{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "expected-needle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sagemaker.session import s3_input, Session\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "incomplete-bumper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-1\n"
     ]
    }
   ],
   "source": [
    "#Set the name for s3 bucket, where you will store all the files and the model.\n",
    "\n",
    "bucket_name = 'spamclassifierbucket'\n",
    "\n",
    "#Get the current AWS Region where the SageMaker notebook instance is running.\n",
    "my_region = boto3.session.Session().region_name\n",
    "print(my_region)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "brief-plate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3 bucket created successfully\n"
     ]
    }
   ],
   "source": [
    "#Create S3 Bucket for the sagemaker notebook instance in the specific region where it is running\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "try:\n",
    "    if my_region == 'us-east-1':\n",
    "        s3.create_bucket(Bucket=bucket_name)\n",
    "    print(\"s3 bucket created successfully\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"s3 bucket not created. Error: \", e)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "moral-rebecca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://spamclassifierbucket/spam-files/output\n"
     ]
    }
   ],
   "source": [
    "#Set a folder path to store the data and the models\n",
    "s3_prefix = \"spam-files\"\n",
    "s3_outpath = 's3://{}/{}/output'.format(bucket_name,s3_prefix)\n",
    "\n",
    "print(s3_outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sized-silence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  labels                                           messages\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Upload the data or text file and store it in S3 bucket\n",
    "\n",
    "data = pd.read_csv('SMSSpamCollection.txt', sep=\"\\t\", header=None, names = ['labels', 'messages'])\n",
    "\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "accurate-oxygen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to pre-process the dataset \n",
    "#1. Convert the labels into numerical values 0's and 1's\n",
    "#2. Use TF-IDF pipeline to pre-process the data\n",
    "\n",
    "data['labels'] = label_binarize(data['labels'],classes = ['ham','spam'])\n",
    "\n",
    "#convert messages into tf_idf\n",
    "tfidf = Pipeline([('cv',CountVectorizer()), ('tfidf_transformer', TfidfTransformer(smooth_idf=True,use_idf=True))])\n",
    "tfidf_vector = pd.DataFrame(tfidf.fit_transform(data['messages']).todense())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "literary-thumb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into train, validation and test datasets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(tfidf_vector, data['labels'], test_size=0.3, random_state=42)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "pretty-rochester",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sagemaker.session import s3_input, Session\n",
    "\n",
    "# We are concatenating the X_train, Y_train in such a way that target label is the first column and then converting \n",
    "# it into a csv file.\n",
    "pd.concat([Y_train, X_train], axis=1).to_csv(os.path.join('train.csv'), header=False, index=False)\n",
    "\n",
    "# Next, we upload this csv file into the s3 bucket which we created earlier. This file will be under a separate folder\n",
    "# called train folder within the s3 bucket.\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(s3_prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "\n",
    "# Use the TrainingInput class to configure a data input flow for training by using the uploaded training dataset. \n",
    "# This will be used during model training\n",
    "s3_input_train = sagemaker.TrainingInput(s3_data='s3://{}/{}/train'.format(bucket_name, s3_prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "comparative-arizona",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Similar to previous step we follow the same for the test data\n",
    "#Create csv file for test data, create a folder path within the s3 bucket for test and upload the file in that folder.\n",
    "\n",
    "\n",
    "pd.concat([Y_test, X_test], axis=1).to_csv(os.path.join('test.csv'), header=False, index=False)\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(s3_prefix, 'test/test.csv')).upload_file('test.csv')\n",
    "\n",
    "# Use the TrainingInput class to configure a data input flow for testing by using the uploaded testing dataset. \n",
    "s3_input_test = sagemaker.TrainingInput(s3_data='s3://{}/{}/test'.format(bucket_name, s3_prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "naked-decline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Create csv file for validation data, create a folder path within the s3 bucket for validation and upload the file in that folder.\n",
    "\n",
    "pd.concat([Y_val, X_val], axis=1).to_csv(os.path.join('val.csv'), header=False, index=False)\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(s3_prefix, 'val/val.csv')).upload_file('val.csv')\n",
    "\n",
    "# Use the TrainingInput class to configure a data input flow for validation by using the uploaded validation dataset. \n",
    "# Will used during model training\n",
    "s3_input_val = sagemaker.TrainingInput(s3_data='s3://{}/{}/val'.format(bucket_name, s3_prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "understanding-sleep",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "intermediate-serbia",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The method get_image_uri has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "# Build a model using XGBoost inbuilt algorithm\n",
    "# Use the xgboost algorithm image and run it to create an xgboost container\n",
    "\n",
    "container = get_image_uri(boto3.Session().region_name,'xgboost',repo_version='1.2-1')\n",
    "\n",
    "hyperparameters ={\n",
    "\"max_depth\": 5,\n",
    "\"eta\": 0.2,\n",
    "\"gamma\": 2,\n",
    "\"min_child_weight\": 5,\n",
    "\"subsample\": 0.8,\n",
    "\"objective\": \"binary:logistic\",\n",
    "\"early_stopping_rounds\": 25,\n",
    "\"num_round\": 150,\n",
    "}\n",
    "\n",
    "#constructing a SageMaker estimator for training that calls the xgboost-container.\n",
    "\n",
    "#Estimators are a high-level interface for SageMaker training to handle end-to-end Amazon SageMaker training \n",
    "#and deployment tasks. \n",
    "\n",
    "estimator = sagemaker.estimator.Estimator(image_uri=container, \n",
    "                                          hyperparameters=hyperparameters,\n",
    "                                          role=sagemaker.get_execution_role(),\n",
    "                                          instance_count=1, \n",
    "                                          instance_type='ml.m4.xlarge', \n",
    "                                          output_path=s3_outpath,\n",
    "                                          sagemaker_session = sagemaker.Session())\n",
    "\n",
    "#image_uri – Specify the training container image URI.\n",
    "\n",
    "#role – The AWS Identity and Access Management (IAM) role that SageMaker uses to perform tasks on your behalf.\n",
    "\n",
    "#train_instance_count and train_instance_type – The type and number of Amazon EC2 ML compute instances to use for training. \n",
    "#                                               In this we use a single ml.m4.xlarge instance,\n",
    "#                                               which has 4 CPUs, 16 GB of memory, an Amazon Elastic Block Store \n",
    "#                                               (Amazon EBS) storage, and a high network performance. \n",
    "\n",
    "#train_volume_size – The size, in GB, of the EBS storage volume to attach to the training instance.\n",
    "\n",
    "#sagemaker_session – The session object that manages interactions with SageMaker API operations \n",
    "#                    and other AWS service that the training job uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "specific-combine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-08 23:19:36 Starting - Starting the training job...\n",
      "2021-03-08 23:20:00 Starting - Launching requested ML instancesProfilerReport-1615245575: InProgress\n",
      "......\n",
      "2021-03-08 23:21:01 Starting - Preparing the instances for training.........\n",
      "2021-03-08 23:22:24 Downloading - Downloading input data\n",
      "2021-03-08 23:22:24 Training - Downloading the training image.....\u001b[34m[2021-03-08 23:23:14.509 ip-10-2-167-168.ec2.internal:1 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 2730 rows\u001b[0m\n",
      "\u001b[34mINFO:root:Validation matrix has 1170 rows\u001b[0m\n",
      "\u001b[34m[23:23:16] WARNING: ../src/learner.cc:516: \u001b[0m\n",
      "\u001b[34mParameters: { early_stopping_rounds } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.05348#011validation-error:0.05897\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.05275#011validation-error:0.06239\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.05238#011validation-error:0.05641\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.05128#011validation-error:0.05641\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.05018#011validation-error:0.05299\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.04872#011validation-error:0.05043\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.04652#011validation-error:0.04615\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.04396#011validation-error:0.04786\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.04139#011validation-error:0.04530\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.03846#011validation-error:0.04444\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.03956#011validation-error:0.04530\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.03883#011validation-error:0.04103\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.03809#011validation-error:0.04444\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.03626#011validation-error:0.04530\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.03553#011validation-error:0.04444\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.03407#011validation-error:0.04188\u001b[0m\n",
      "\n",
      "2021-03-08 23:23:22 Training - Training image download completed. Training in progress.\u001b[34m[16]#011train-error:0.03187#011validation-error:0.03846\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.03150#011validation-error:0.03590\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.03077#011validation-error:0.03846\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.03187#011validation-error:0.03675\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.03077#011validation-error:0.03761\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.02967#011validation-error:0.03675\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.02857#011validation-error:0.03675\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.02711#011validation-error:0.03419\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.02637#011validation-error:0.03162\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.02747#011validation-error:0.02992\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.02564#011validation-error:0.03077\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.02637#011validation-error:0.03162\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.02637#011validation-error:0.03162\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.02564#011validation-error:0.03162\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.02491#011validation-error:0.03162\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.02454#011validation-error:0.03248\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.02491#011validation-error:0.03248\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.02454#011validation-error:0.03248\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.02454#011validation-error:0.03333\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.02381#011validation-error:0.03248\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.02418#011validation-error:0.03248\u001b[0m\n",
      "\u001b[34m[37]#011train-error:0.02454#011validation-error:0.03162\u001b[0m\n",
      "\u001b[34m[38]#011train-error:0.02454#011validation-error:0.03162\u001b[0m\n",
      "\u001b[34m[39]#011train-error:0.02454#011validation-error:0.03162\u001b[0m\n",
      "\u001b[34m[40]#011train-error:0.02454#011validation-error:0.03162\u001b[0m\n",
      "\u001b[34m[41]#011train-error:0.02454#011validation-error:0.03248\u001b[0m\n",
      "\u001b[34m[42]#011train-error:0.02454#011validation-error:0.03248\u001b[0m\n",
      "\u001b[34m[43]#011train-error:0.02491#011validation-error:0.03248\u001b[0m\n",
      "\u001b[34m[44]#011train-error:0.02491#011validation-error:0.03333\u001b[0m\n",
      "\u001b[34m[45]#011train-error:0.02418#011validation-error:0.03248\u001b[0m\n",
      "\u001b[34m[46]#011train-error:0.02454#011validation-error:0.03333\u001b[0m\n",
      "\u001b[34m[47]#011train-error:0.02454#011validation-error:0.03419\u001b[0m\n",
      "\u001b[34m[48]#011train-error:0.02418#011validation-error:0.03504\u001b[0m\n",
      "\u001b[34m[49]#011train-error:0.02381#011validation-error:0.03419\u001b[0m\n",
      "\u001b[34m[50]#011train-error:0.02418#011validation-error:0.03504\u001b[0m\n",
      "\n",
      "2021-03-08 23:24:03 Uploading - Uploading generated training model\n",
      "2021-03-08 23:24:03 Completed - Training job completed\n",
      "Training seconds: 98\n",
      "Billable seconds: 98\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({\"train\":s3_input_train, \"validation\":s3_input_val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-player",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the model\n",
    "\n",
    "# 1. Deploy the Model to SageMaker Hosting Services, Amazon EC2\n",
    "# 2. Use SageMaker Predictor to Reuse the Hosted Endpoint\n",
    "# 3. Make Prediction with Batch Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "genuine-greensboro",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's try 3rd option first since we have a test file already to make batch predictions\n",
    "# Instead of hosting an endpoint in production, we can run one-time batch inference job to make predictions on a test data.\n",
    "\n",
    "# In this option, we use the Sagemaker's Batch Transform functionality to test the model.\n",
    "# The test data is split into batches and fed to the model. \n",
    "# The predictions from each batch is later merged to determine the model accuracy.\n",
    "\n",
    "#create a transformer object\n",
    "\n",
    "xgb_transformer = estimator.transformer(instance_count=1, instance_type='ml.m4.xlarge')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "animated-neighbor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................................\u001b[34m[2021-03-09:00:18:04:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2021-03-09:00:18:04:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2021-03-09:00:18:04:INFO] nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\n",
      "\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\n",
      "\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "\n",
      "    keepalive_timeout 3;\n",
      "\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m2021/03/09 00:18:04 [crit] 19#19: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Mar/2021:00:18:04 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Mar/2021:00:18:04 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2021/03/09 00:18:04 [crit] 19#19: *3 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m[2021-03-09 00:18:04 +0000] [18] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[34m[2021-03-09 00:18:04 +0000] [18] [INFO] Listening at: unix:/tmp/gunicorn.sock (18)\u001b[0m\n",
      "\u001b[34m[2021-03-09 00:18:04 +0000] [18] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-03-09 00:18:04 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[34m[2021-03-09 00:18:04 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[34m[2021-03-09 00:18:04 +0000] [27] [INFO] Booting worker with pid: 27\u001b[0m\n",
      "\u001b[34m[2021-03-09 00:18:05 +0000] [28] [INFO] Booting worker with pid: 28\u001b[0m\n",
      "\u001b[34m[2021-03-09:00:18:06:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Mar/2021:00:18:06 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Mar/2021:00:18:06 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2021-03-09:00:18:07:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2021-03-09:00:18:07:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2021-03-09:00:18:07:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2021-03-09:00:18:07:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2021-03-09:00:18:07:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2021-03-09:00:18:07:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2021-03-09:00:18:07:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Mar/2021:00:18:09 +0000] \"POST /invocations HTTP/1.1\" 200 3658 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Mar/2021:00:18:09 +0000] \"POST /invocations HTTP/1.1\" 200 3644 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Mar/2021:00:18:09 +0000] \"POST /invocations HTTP/1.1\" 200 3657 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Mar/2021:00:18:09 +0000] \"POST /invocations HTTP/1.1\" 200 3657 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2021-03-09:00:18:09:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2021-03-09:00:18:09:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2021-03-09:00:18:09:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2021-03-09:00:18:09:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Mar/2021:00:18:11 +0000] \"POST /invocations HTTP/1.1\" 200 3628 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Mar/2021:00:18:11 +0000] \"POST /invocations HTTP/1.1\" 200 3641 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Mar/2021:00:18:11 +0000] \"POST /invocations HTTP/1.1\" 200 3654 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2021-03-09:00:18:11:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Mar/2021:00:18:11 +0000] \"POST /invocations HTTP/1.1\" 200 3642 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2021-03-09:00:18:11:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Mar/2021:00:18:11 +0000] \"POST /invocations HTTP/1.1\" 200 1240 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Mar/2021:00:18:12 +0000] \"POST /invocations HTTP/1.1\" 200 3635 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2021-03-09T00:18:06.814:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initiate the batch transform job by executing the transform() method of the xgb_transformer object.\n",
    "\n",
    "# Specify S3 bucket URIs of input and output for the batch transform job \n",
    "X_test.to_csv(os.path.join('test_data.csv'), header=False, index=False)\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(s3_prefix, 'batchtest/test_data.csv')).upload_file('test_data.csv')\n",
    "batch_input = 's3://{}/{}/batchtest'.format(bucket_name, s3_prefix)\n",
    "batch_output = 's3://{}/{}/batch-prediction'.format(bucket_name, s3_prefix)\n",
    "\n",
    "\n",
    "xgb_transformer.transform(data=batch_input , data_type='S3Prefix' , content_type='text/csv', split_type='Line')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "purple-latin",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2021-03-09:00:18:04:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2021-03-09:00:18:04:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2021-03-09:00:18:04:INFO] nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[35m[2021-03-09:00:18:04:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2021-03-09:00:18:04:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2021-03-09:00:18:04:INFO] nginx config: \u001b[0m\n",
      "\u001b[35mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\n",
      "\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\n",
      "\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[35mdaemon off;\u001b[0m\n",
      "\u001b[35mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[35merror_log  /dev/stderr;\n",
      "\u001b[0m\n",
      "\u001b[35mworker_rlimit_nofile 4096;\n",
      "\u001b[0m\n",
      "\u001b[35mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[35m}\n",
      "\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "\n",
      "    keepalive_timeout 3;\n",
      "\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m2021/03/09 00:18:04 [crit] 19#19: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Mar/2021:00:18:04 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Mar/2021:00:18:04 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2021/03/09 00:18:04 [crit] 19#19: *3 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m[2021-03-09 00:18:04 +0000] [18] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[34m[2021-03-09 00:18:04 +0000] [18] [INFO] Listening at: unix:/tmp/gunicorn.sock (18)\u001b[0m\n",
      "\u001b[34m[2021-03-09 00:18:04 +0000] [18] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-03-09 00:18:04 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[35mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "\n",
      "    keepalive_timeout 3;\n",
      "\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "\n",
      "  }\u001b[0m\n",
      "\u001b[35m}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m2021/03/09 00:18:04 [crit] 19#19: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Mar/2021:00:18:04 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Mar/2021:00:18:04 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2021/03/09 00:18:04 [crit] 19#19: *3 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m[2021-03-09 00:18:04 +0000] [18] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[35m[2021-03-09 00:18:04 +0000] [18] [INFO] Listening at: unix:/tmp/gunicorn.sock (18)\u001b[0m\n",
      "\u001b[35m[2021-03-09 00:18:04 +0000] [18] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2021-03-09 00:18:04 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[34m[2021-03-09 00:18:04 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[34m[2021-03-09 00:18:04 +0000] [27] [INFO] Booting worker with pid: 27\u001b[0m\n",
      "\u001b[34m[2021-03-09 00:18:05 +0000] [28] [INFO] Booting worker with pid: 28\u001b[0m\n",
      "\u001b[35m[2021-03-09 00:18:04 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[35m[2021-03-09 00:18:04 +0000] [27] [INFO] Booting worker with pid: 27\u001b[0m\n",
      "\u001b[35m[2021-03-09 00:18:05 +0000] [28] [INFO] Booting worker with pid: 28\u001b[0m\n",
      "\u001b[34m[2021-03-09:00:18:06:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Mar/2021:00:18:06 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Mar/2021:00:18:06 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2021-03-09:00:18:07:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2021-03-09:00:18:07:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2021-03-09:00:18:07:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2021-03-09:00:18:07:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2021-03-09:00:18:07:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2021-03-09:00:18:07:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2021-03-09:00:18:06:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Mar/2021:00:18:06 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Mar/2021:00:18:06 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2021-03-09:00:18:07:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2021-03-09:00:18:07:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2021-03-09:00:18:07:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2021-03-09:00:18:07:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2021-03-09:00:18:07:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2021-03-09:00:18:07:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2021-03-09:00:18:07:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2021-03-09:00:18:07:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Mar/2021:00:18:09 +0000] \"POST /invocations HTTP/1.1\" 200 3658 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Mar/2021:00:18:09 +0000] \"POST /invocations HTTP/1.1\" 200 3644 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Mar/2021:00:18:09 +0000] \"POST /invocations HTTP/1.1\" 200 3657 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Mar/2021:00:18:09 +0000] \"POST /invocations HTTP/1.1\" 200 3657 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Mar/2021:00:18:09 +0000] \"POST /invocations HTTP/1.1\" 200 3658 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Mar/2021:00:18:09 +0000] \"POST /invocations HTTP/1.1\" 200 3644 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Mar/2021:00:18:09 +0000] \"POST /invocations HTTP/1.1\" 200 3657 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Mar/2021:00:18:09 +0000] \"POST /invocations HTTP/1.1\" 200 3657 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2021-03-09:00:18:09:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2021-03-09:00:18:09:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2021-03-09:00:18:09:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2021-03-09:00:18:09:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2021-03-09:00:18:09:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2021-03-09:00:18:09:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2021-03-09:00:18:09:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2021-03-09:00:18:09:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[32m2021-03-09T00:18:06.814:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Mar/2021:00:18:11 +0000] \"POST /invocations HTTP/1.1\" 200 3628 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Mar/2021:00:18:11 +0000] \"POST /invocations HTTP/1.1\" 200 3628 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Mar/2021:00:18:11 +0000] \"POST /invocations HTTP/1.1\" 200 3641 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Mar/2021:00:18:11 +0000] \"POST /invocations HTTP/1.1\" 200 3641 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Mar/2021:00:18:11 +0000] \"POST /invocations HTTP/1.1\" 200 3654 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Mar/2021:00:18:11 +0000] \"POST /invocations HTTP/1.1\" 200 3654 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2021-03-09:00:18:11:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Mar/2021:00:18:11 +0000] \"POST /invocations HTTP/1.1\" 200 3642 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2021-03-09:00:18:11:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Mar/2021:00:18:11 +0000] \"POST /invocations HTTP/1.1\" 200 1240 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2021-03-09:00:18:11:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Mar/2021:00:18:11 +0000] \"POST /invocations HTTP/1.1\" 200 3642 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2021-03-09:00:18:11:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Mar/2021:00:18:11 +0000] \"POST /invocations HTTP/1.1\" 200 1240 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Mar/2021:00:18:12 +0000] \"POST /invocations HTTP/1.1\" 200 3635 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Mar/2021:00:18:12 +0000] \"POST /invocations HTTP/1.1\" 200 3635 \"-\" \"Go-http-client/1.1\"\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "xgb_transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "spatial-manhattan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy: s3://sagemaker-us-east-1-124958237186/sagemaker-xgboost-2021-03-09-00-11-32-487/test_data.csv.out to s3://spamclassifierbucket/spam-files/batch-prediction/test_data.csv.out\r\n"
     ]
    }
   ],
   "source": [
    "#When the batch transform job is complete, SageMaker creates the test.csv.out prediction data saved in the batch_output path\n",
    "#Download the test.csv.out to current directory\n",
    "!aws s3 cp --recursive $xgb_transformer.output_path $batch_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "sustained-sauce",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    predictions = pd.read_csv(os.path.join('s3://spamclassifierbucket/spam-files/batch-prediction/', 'test_data.csv.out'), header=None)\n",
    "    predictions = [round(num) for num in predictions.squeeze().values]\n",
    "except Exception as e:\n",
    "    print(\"error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "gorgeous-repeat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9712918660287081"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "accuracy_score(Y_test, predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "genetic-entrance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1439    9]\n",
      " [  39  185]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "informational-image",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      1448\n",
      "           1       0.95      0.83      0.89       224\n",
      "\n",
      "    accuracy                           0.97      1672\n",
      "   macro avg       0.96      0.91      0.93      1672\n",
      "weighted avg       0.97      0.97      0.97      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "broke-viking",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "# Clean up \n",
    "sagemaker.Session().delete_endpoint(xgb_predictor.endpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "million-start",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ResponseMetadata': {'RequestId': 'V0HAV84HJD1585EF',\n",
       "   'HostId': 'pGg24RSY4vWe+yMvNtlP8dXuQz6adMYDmmhQF7nz7FP52JCD0rkRRm6ri5CgEKkH+mmupj8c2y8=',\n",
       "   'HTTPStatusCode': 200,\n",
       "   'HTTPHeaders': {'x-amz-id-2': 'pGg24RSY4vWe+yMvNtlP8dXuQz6adMYDmmhQF7nz7FP52JCD0rkRRm6ri5CgEKkH+mmupj8c2y8=',\n",
       "    'x-amz-request-id': 'V0HAV84HJD1585EF',\n",
       "    'date': 'Tue, 09 Mar 2021 01:17:55 GMT',\n",
       "    'content-type': 'application/xml',\n",
       "    'transfer-encoding': 'chunked',\n",
       "    'server': 'AmazonS3',\n",
       "    'connection': 'close'},\n",
       "   'RetryAttempts': 0},\n",
       "  'Deleted': [{'Key': 'spam-files/output/sagemaker-xgboost-2021-03-08-23-19-35-778/rule-output/ProfilerReport-1615245575/profiler-output/profiler-reports/BatchSize.json'},\n",
       "   {'Key': 'spam-files/batchtest/test_data.csv'},\n",
       "   {'Key': 'spam-files/output/sagemaker-xgboost-2021-03-08-23-19-35-778/profiler-output/system/incremental/2021030823/1615245780.algo-1.json'},\n",
       "   {'Key': 'spam-files/output/sagemaker-xgboost-2021-03-08-23-19-35-778/output/model.tar.gz'},\n",
       "   {'Key': 'spam-files/output/sagemaker-xgboost-2021-03-08-23-19-35-778/rule-output/ProfilerReport-1615245575/profiler-output/profiler-reports/CPUBottleneck.json'},\n",
       "   {'Key': 'spam-files/output/sagemaker-xgboost-2021-03-08-23-19-35-778/profiler-output/system/incremental/2021030823/1615245720.algo-1.json'},\n",
       "   {'Key': 'spam-files/output/sagemaker-xgboost-2021-03-08-23-19-35-778/rule-output/ProfilerReport-1615245575/profiler-output/profiler-reports/Dataloader.json'},\n",
       "   {'Key': 'spam-files/output/sagemaker-xgboost-2021-03-08-23-19-35-778/rule-output/ProfilerReport-1615245575/profiler-output/profiler-report.html'},\n",
       "   {'Key': 'spam-files/output/sagemaker-xgboost-2021-03-08-23-19-35-778/rule-output/ProfilerReport-1615245575/profiler-output/profiler-reports/GPUMemoryIncrease.json'},\n",
       "   {'Key': 'spam-files/output/sagemaker-xgboost-2021-03-08-23-19-35-778/rule-output/ProfilerReport-1615245575/profiler-output/profiler-reports/IOBottleneck.json'},\n",
       "   {'Key': 'spam-files/train/train.csv'},\n",
       "   {'Key': 'spam-files/output/sagemaker-xgboost-2021-03-08-23-19-35-778/rule-output/ProfilerReport-1615245575/profiler-output/profiler-reports/LowGPUUtilization.json'},\n",
       "   {'Key': 'spam-files/output/sagemaker-xgboost-2021-03-08-23-19-35-778/rule-output/ProfilerReport-1615245575/profiler-output/profiler-reports/OverallFrameworkMetrics.json'},\n",
       "   {'Key': 'spam-files/batch-prediction/test_data.csv.out'},\n",
       "   {'Key': 'spam-files/output/sagemaker-xgboost-2021-03-08-23-19-35-778/profiler-output/system/training_job_end.ts'},\n",
       "   {'Key': 'spam-files/val/val.csv'},\n",
       "   {'Key': 'spam-files/output/sagemaker-xgboost-2021-03-08-23-19-35-778/profiler-output/framework/training_job_end.ts'},\n",
       "   {'Key': 'spam-files/output/sagemaker-xgboost-2021-03-08-23-19-35-778/rule-output/ProfilerReport-1615245575/profiler-output/profiler-reports/StepOutlier.json'},\n",
       "   {'Key': 'spam-files/output/sagemaker-xgboost-2021-03-08-23-19-35-778/rule-output/ProfilerReport-1615245575/profiler-output/profiler-reports/LoadBalancing.json'},\n",
       "   {'Key': 'spam-files/output/sagemaker-xgboost-2021-03-08-23-19-35-778/rule-output/ProfilerReport-1615245575/profiler-output/profiler-reports/MaxInitializationTime.json'},\n",
       "   {'Key': 'spam-files/output/sagemaker-xgboost-2021-03-08-23-19-35-778/rule-output/ProfilerReport-1615245575/profiler-output/profiler-reports/OverallSystemUsage.json'},\n",
       "   {'Key': 'spam-files/output/sagemaker-xgboost-2021-03-08-23-19-35-778/rule-output/ProfilerReport-1615245575/profiler-output/profiler-report.ipynb'},\n",
       "   {'Key': 'spam-files/test/test.csv'}]}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_to_delete = boto3.resource('s3').Bucket(bucket_name)\n",
    "bucket_to_delete.objects.all().delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressed-crown",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
